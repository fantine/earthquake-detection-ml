{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare TensorFlow records manifest files\n",
    "\n",
    "Since we do not expect all events to be detectable by our fiber-optic DAS array, we select events above a certain amplitude threshold. We select which event and noise samples to include in the TensorFlow record files used for training and evaluating the machine learning model. We save the indices of these data samples in a manifest file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>focal_time</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>distance</th>\n",
       "      <th>duration</th>\n",
       "      <th>evaluation_mode</th>\n",
       "      <th>evaluation_status</th>\n",
       "      <th>onset</th>\n",
       "      <th>velocity_estimate</th>\n",
       "      <th>datetime</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>has_seismometer_data</th>\n",
       "      <th>has_das_data</th>\n",
       "      <th>local_amplitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>72688791</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2016-09-02 03:13:55.760000</td>\n",
       "      <td>2016-09-02 03:13:58.240000</td>\n",
       "      <td>37.388000</td>\n",
       "      <td>-122.272835</td>\n",
       "      <td>-122.272835</td>\n",
       "      <td>1.00</td>\n",
       "      <td>12229.080</td>\n",
       "      <td>7.1269</td>\n",
       "      <td>manual</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>impulsive</td>\n",
       "      <td>4929.2812</td>\n",
       "      <td>2016-09-02 03:13:58.218031</td>\n",
       "      <td>241.905850</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>91.871735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>72688876</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2016-09-02 05:10:33.570000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.978832</td>\n",
       "      <td>-121.639660</td>\n",
       "      <td>-121.639660</td>\n",
       "      <td>1.86</td>\n",
       "      <td>69224.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-09-02 05:10:45.886511</td>\n",
       "      <td>136.247300</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>7.867574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>72689111</td>\n",
       "      <td>quarry blast</td>\n",
       "      <td>2016-09-02 17:26:32.670000</td>\n",
       "      <td>2016-09-02 17:26:36.040000</td>\n",
       "      <td>37.324000</td>\n",
       "      <td>-122.101830</td>\n",
       "      <td>-122.101830</td>\n",
       "      <td>1.30</td>\n",
       "      <td>13406.592</td>\n",
       "      <td>15.4430</td>\n",
       "      <td>manual</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>emergent</td>\n",
       "      <td>3978.3070</td>\n",
       "      <td>2016-09-02 17:26:35.952630</td>\n",
       "      <td>150.703230</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>144.868800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>72689151</td>\n",
       "      <td>quarry blast</td>\n",
       "      <td>2016-09-02 19:22:06.220000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.893833</td>\n",
       "      <td>-121.617500</td>\n",
       "      <td>-121.617500</td>\n",
       "      <td>1.71</td>\n",
       "      <td>77405.836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-09-02 19:22:25.172631</td>\n",
       "      <td>139.987780</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4.184556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>72689361</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2016-09-03 06:01:49.650000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.909832</td>\n",
       "      <td>-121.853165</td>\n",
       "      <td>-121.853165</td>\n",
       "      <td>1.35</td>\n",
       "      <td>61244.918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-09-03 06:02:00.721334</td>\n",
       "      <td>27.995693</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.326677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5764</th>\n",
       "      <td>5764</td>\n",
       "      <td>73312476</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2019-12-07 19:18:51.490000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.043835</td>\n",
       "      <td>-121.903000</td>\n",
       "      <td>-121.903000</td>\n",
       "      <td>2.06</td>\n",
       "      <td>74234.360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-07 19:19:04.556444</td>\n",
       "      <td>19.340443</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>10.427045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5765</th>\n",
       "      <td>5765</td>\n",
       "      <td>73312481</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2019-12-07 19:34:00.340000</td>\n",
       "      <td>2019-12-07 19:34:11.600000</td>\n",
       "      <td>37.116833</td>\n",
       "      <td>-121.522500</td>\n",
       "      <td>-121.522500</td>\n",
       "      <td>2.70</td>\n",
       "      <td>67801.750</td>\n",
       "      <td>50.5100</td>\n",
       "      <td>manual</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>impulsive</td>\n",
       "      <td>6018.6455</td>\n",
       "      <td>2019-12-07 19:34:12.437310</td>\n",
       "      <td>120.705025</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>57.402836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5766</th>\n",
       "      <td>5766</td>\n",
       "      <td>73312566</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2019-12-08 02:38:59.140000</td>\n",
       "      <td>2019-12-08 02:39:06.280000</td>\n",
       "      <td>37.730500</td>\n",
       "      <td>-122.136500</td>\n",
       "      <td>-122.136500</td>\n",
       "      <td>2.26</td>\n",
       "      <td>33886.727</td>\n",
       "      <td>29.7800</td>\n",
       "      <td>manual</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>impulsive</td>\n",
       "      <td>4744.4526</td>\n",
       "      <td>2019-12-08 02:39:05.631518</td>\n",
       "      <td>5.923369</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>123.036560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5767</th>\n",
       "      <td>5767</td>\n",
       "      <td>73312731</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2019-12-08 20:06:06.480000</td>\n",
       "      <td>2019-12-08 20:06:14.140000</td>\n",
       "      <td>37.677834</td>\n",
       "      <td>-122.508500</td>\n",
       "      <td>-122.508500</td>\n",
       "      <td>1.48</td>\n",
       "      <td>42149.785</td>\n",
       "      <td>12.4950</td>\n",
       "      <td>manual</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>emergent</td>\n",
       "      <td>5497.7285</td>\n",
       "      <td>2019-12-08 20:06:14.408352</td>\n",
       "      <td>313.275180</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>11.679759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5768</th>\n",
       "      <td>5768</td>\n",
       "      <td>73313016</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2019-12-09 21:15:03.240000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.011000</td>\n",
       "      <td>-122.214000</td>\n",
       "      <td>-122.214000</td>\n",
       "      <td>0.81</td>\n",
       "      <td>65324.895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-09 21:15:14.951393</td>\n",
       "      <td>357.028350</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.813408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5769 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        id          type                  focal_time  \\\n",
       "0              0  72688791    earthquake  2016-09-02 03:13:55.760000   \n",
       "1              1  72688876    earthquake  2016-09-02 05:10:33.570000   \n",
       "2              2  72689111  quarry blast  2016-09-02 17:26:32.670000   \n",
       "3              3  72689151  quarry blast  2016-09-02 19:22:06.220000   \n",
       "4              4  72689361    earthquake  2016-09-03 06:01:49.650000   \n",
       "...          ...       ...           ...                         ...   \n",
       "5764        5764  73312476    earthquake  2019-12-07 19:18:51.490000   \n",
       "5765        5765  73312481    earthquake  2019-12-07 19:34:00.340000   \n",
       "5766        5766  73312566    earthquake  2019-12-08 02:38:59.140000   \n",
       "5767        5767  73312731    earthquake  2019-12-08 20:06:06.480000   \n",
       "5768        5768  73313016    earthquake  2019-12-09 21:15:03.240000   \n",
       "\n",
       "                    arrival_time   latitude   longitude       depth  \\\n",
       "0     2016-09-02 03:13:58.240000  37.388000 -122.272835 -122.272835   \n",
       "1                            NaN  36.978832 -121.639660 -121.639660   \n",
       "2     2016-09-02 17:26:36.040000  37.324000 -122.101830 -122.101830   \n",
       "3                            NaN  36.893833 -121.617500 -121.617500   \n",
       "4                            NaN  37.909832 -121.853165 -121.853165   \n",
       "...                          ...        ...         ...         ...   \n",
       "5764                         NaN  38.043835 -121.903000 -121.903000   \n",
       "5765  2019-12-07 19:34:11.600000  37.116833 -121.522500 -121.522500   \n",
       "5766  2019-12-08 02:39:06.280000  37.730500 -122.136500 -122.136500   \n",
       "5767  2019-12-08 20:06:14.140000  37.677834 -122.508500 -122.508500   \n",
       "5768                         NaN  38.011000 -122.214000 -122.214000   \n",
       "\n",
       "      magnitude   distance  duration evaluation_mode evaluation_status  \\\n",
       "0          1.00  12229.080    7.1269          manual          reviewed   \n",
       "1          1.86  69224.750       NaN             NaN               NaN   \n",
       "2          1.30  13406.592   15.4430          manual          reviewed   \n",
       "3          1.71  77405.836       NaN             NaN               NaN   \n",
       "4          1.35  61244.918       NaN             NaN               NaN   \n",
       "...         ...        ...       ...             ...               ...   \n",
       "5764       2.06  74234.360       NaN             NaN               NaN   \n",
       "5765       2.70  67801.750   50.5100          manual          reviewed   \n",
       "5766       2.26  33886.727   29.7800          manual          reviewed   \n",
       "5767       1.48  42149.785   12.4950          manual          reviewed   \n",
       "5768       0.81  65324.895       NaN             NaN               NaN   \n",
       "\n",
       "          onset  velocity_estimate                    datetime     azimuth  \\\n",
       "0     impulsive          4929.2812  2016-09-02 03:13:58.218031  241.905850   \n",
       "1           NaN                NaN  2016-09-02 05:10:45.886511  136.247300   \n",
       "2      emergent          3978.3070  2016-09-02 17:26:35.952630  150.703230   \n",
       "3           NaN                NaN  2016-09-02 19:22:25.172631  139.987780   \n",
       "4           NaN                NaN  2016-09-03 06:02:00.721334   27.995693   \n",
       "...         ...                ...                         ...         ...   \n",
       "5764        NaN                NaN  2019-12-07 19:19:04.556444   19.340443   \n",
       "5765  impulsive          6018.6455  2019-12-07 19:34:12.437310  120.705025   \n",
       "5766  impulsive          4744.4526  2019-12-08 02:39:05.631518    5.923369   \n",
       "5767   emergent          5497.7285  2019-12-08 20:06:14.408352  313.275180   \n",
       "5768        NaN                NaN  2019-12-09 21:15:14.951393  357.028350   \n",
       "\n",
       "      has_seismometer_data  has_das_data  local_amplitude  \n",
       "0                     True         False        91.871735  \n",
       "1                     True         False         7.867574  \n",
       "2                     True         False       144.868800  \n",
       "3                     True          True         4.184556  \n",
       "4                     True          True         3.326677  \n",
       "...                    ...           ...              ...  \n",
       "5764                  True          True        10.427045  \n",
       "5765                  True          True        57.402836  \n",
       "5766                  True          True       123.036560  \n",
       "5767                  True          True        11.679759  \n",
       "5768                  True         False         0.813408  \n",
       "\n",
       "[5769 rows x 20 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the event and noise catalogs\n",
    "df_events = pd.read_csv('catalog/earthquake_catalog.csv')\n",
    "df_noise = pd.read_csv('catalog/noise_catalog.csv')\n",
    "\n",
    "df_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where the processed data windows are stored.\n",
    "data_dir = '/scratch/earthquake-detection-ml/processed_data/das/'\n",
    "\n",
    "# Amplitude threshold in nano-strain.\n",
    "threshold = 40  \n",
    "# Ratio of noise to event windows.\n",
    "noise_ratio = 1\n",
    "# Prefix for naming the manifest files. \n",
    "manifest_prefix = 'das_threshold40_balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing missing data 5769\n",
      "After removing missing data 4519\n"
     ]
    }
   ],
   "source": [
    "def remove_missing_data(df):\n",
    "  df = df[df.has_das_data == True]\n",
    "  return df[df.has_seismometer_data == True]\n",
    "\n",
    "print('Before removing missing data', len(df_events))\n",
    "df_events = remove_missing_data(df_events)\n",
    "print('After removing missing data', len(df_events))\n",
    "\n",
    "df_noise = remove_missing_data(df_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events: 555\n"
     ]
    }
   ],
   "source": [
    "def get_event_indices(df, threshold):\n",
    "  indices = list(df[df.local_amplitude >= threshold].index)\n",
    "  random.shuffle(indices)\n",
    "  return indices\n",
    "\n",
    "event_indices = get_event_indices(df_events, threshold)\n",
    "print('Number of events:', len(event_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_event = len(event_indices)\n",
    "noise_indices = df_noise[:n_event * noise_ratio].index\n",
    "\n",
    "n_event_train = int(0.8 * n_event)\n",
    "n_event_eval = int(0.1 * n_event)\n",
    "n_event_test = n_event - n_event_train - n_event_eval\n",
    "\n",
    "n_noise_train = noise_ratio * n_event_train\n",
    "n_noise_eval = noise_ratio * n_event_eval\n",
    "n_noise_test = noise_ratio * n_event_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def _get_filenames(indices, prefix, data_dir, train=True, batch=1000):\n",
    "    filenames = []\n",
    "    for i in indices:\n",
    "        # Data windows with half of the channels.\n",
    "        filename1 = '{}_{:05d}_1.h5'.format(prefix, i)\n",
    "        # Data windows with second of the channels.\n",
    "        filename2 = '{}_{:05d}_2.h5'.format(prefix, i)\n",
    "        # The data files are organized into subfolders of 1000 files.\n",
    "        subdir = '{:05d}'.format((i // batch) * batch)\n",
    "        \n",
    "        filename1 = os.path.join(data_dir, prefix, subdir, filename1)\n",
    "        filename2 = os.path.join(data_dir, prefix, subdir, filename2)\n",
    "        if not os.path.isfile(filename1):\n",
    "            print('file does not exist')\n",
    "            pass\n",
    "        filenames.append(filename1)\n",
    "        if train:\n",
    "            # We include the second half of the channels\n",
    "            # for data augmentation during training.\n",
    "            filenames.append(filename2)\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_event_files = _get_filenames(event_indices[:n_event_train], 'event', data_dir, True)\n",
    "eval_event_files = _get_filenames(event_indices[n_event_train:n_event_train + n_event_eval], 'event', data_dir, False)\n",
    "test_event_files = _get_filenames(event_indices[-n_event_test:], 'event', data_dir, False)\n",
    "\n",
    "train_noise_files = _get_filenames(noise_indices[:n_noise_train], 'noise', data_dir, True)\n",
    "eval_noise_files = _get_filenames(noise_indices[n_noise_train:n_noise_train + n_noise_eval], 'noise', data_dir, False)\n",
    "test_noise_files = _get_filenames(noise_indices[-n_noise_test:], 'noise', data_dir, False)\n",
    "\n",
    "train_files = train_event_files + train_noise_files\n",
    "random.shuffle(train_files)\n",
    "eval_files = eval_event_files + eval_noise_files\n",
    "random.shuffle(eval_files)\n",
    "test_files = test_event_files + test_noise_files\n",
    "random.shuffle(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest_dir = '/scratch/earthquake-detection-ml/tfrecords/manifests'\n",
    "\n",
    "def create_manifest(out_file, filenames):\n",
    "    out_file = os.path.join(manifest_dir, out_file)\n",
    "    print(out_file)\n",
    "    with open(out_file, 'w') as f:\n",
    "        for filename in filenames:\n",
    "            f.write(filename + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_manifest('{}_train_manifest.txt'.format(manifest_prefix), train_files)\n",
    "create_manifest('{}_eval_manifest.txt'.format(manifest_prefix), eval_files)\n",
    "create_manifest('{}_test_manifest.txt'.format(manifest_prefix), test_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
